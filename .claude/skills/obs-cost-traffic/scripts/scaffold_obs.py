#!/usr/bin/env python3
"""
OBS-COST-TRAFFIC Scaffold Script
Generates a production-ready observability, traffic, and cost engineering project
from templates based on environment, tier, and tool selection.

Usage:
    python scaffold_obs.py --name my-platform --tier 1 --env local
    python scaffold_obs.py --name prod-platform --tier 3 --env aws --traffic istio --cost --agents
    python scaffold_obs.py --name enterprise-obs --tier 4 --env multi-cloud --traffic cloudflare --cost --agents

Docs:
    OpenTelemetry: https://opentelemetry.io/docs/
    Grafana Stack: https://grafana.com/docs/
    FinOps: https://www.finops.org/framework/
"""

import argparse
import os
import sys
import shutil
import textwrap
from pathlib import Path
from datetime import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TIER_DESCRIPTIONS = {
    1: "Local Dev (Docker Compose, Prometheus + Grafana + Loki + Tempo + Traefik)",
    2: "VPS / Self-Hosted (HAProxy + NGINX + full OSS stack)",
    3: "Cloud Production (EKS/GKE/AKS + kube-prometheus-stack + OTel Operator)",
    4: "Enterprise Multi-Cloud (Datadog/New Relic + Cloudflare + FinOps governance)",
}

ENV_OPTIONS = {
    "local": "Docker Compose local development",
    "vps": "VPS / Bare Metal self-hosted",
    "aws": "AWS (EKS, CloudWatch, X-Ray, ALB)",
    "gcp": "GCP (GKE, Cloud Monitoring, Cloud Trace, Cloud LB)",
    "azure": "Azure (AKS, Azure Monitor, App Insights, App Gateway)",
    "multi-cloud": "Multi-cloud enterprise (unified OTel + Datadog/New Relic)",
}

TRAFFIC_OPTIONS = {
    "traefik": "Traefik (recommended for Tier 1)",
    "nginx": "NGINX (general purpose L7)",
    "haproxy": "HAProxy (high-performance L4/L7)",
    "istio": "Istio service mesh (K8s Tier 3+)",
    "linkerd": "Linkerd service mesh (lightweight K8s)",
    "cloudflare": "Cloudflare (global traffic + CDN)",
    "alb": "AWS ALB (AWS environments)",
    "cloud-lb": "Cloud Load Balancing (GCP environments)",
    "app-gateway": "Azure Application Gateway (Azure environments)",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# File Generators
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def write_file(path: Path, content: str) -> None:
    """Write content to a file, creating parent directories as needed."""
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(textwrap.dedent(content).lstrip())
    print(f"  âœ“ {path}")


def generate_docker_compose(project: str, env: str, agents: bool, traffic: str) -> str:
    return f'''# {project} â€” Observability Stack (Tier 1: Local Dev)
# Generated by obs-cost-traffic scaffold â€” {datetime.now().strftime("%Y-%m-%d")}
# Docker Compose v2 â€” no "version:" field required

services:
  # â”€â”€ OpenTelemetry Collector â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.116.0
    command: ["--config=/etc/otelcol-contrib/otelcol-config.yaml"]
    volumes:
      - ./observability/otel-collector-config.yaml:/etc/otelcol-contrib/otelcol-config.yaml:ro
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
      - "8889:8889"   # Prometheus metrics (self)
    restart: unless-stopped
    depends_on:
      - loki
      - tempo
      - prometheus

  # â”€â”€ Prometheus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  prometheus:
    image: prom/prometheus:v2.51.0
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.retention.time=7d
      - --web.enable-remote-write-receiver
      - --web.enable-lifecycle
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./observability/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped

  # â”€â”€ Alertmanager â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  alertmanager:
    image: prom/alertmanager:v0.27.0
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
      - --storage.path=/alertmanager
    volumes:
      - ./observability/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    ports:
      - "9093:9093"
    restart: unless-stopped

  # â”€â”€ Loki â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  loki:
    image: grafana/loki:3.1.0
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./observability/loki.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
    restart: unless-stopped

  # â”€â”€ Promtail (log collector) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  promtail:
    image: grafana/promtail:3.1.0
    command: -config.file=/etc/promtail/config.yaml
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
      - ./observability/promtail.yaml:/etc/promtail/config.yaml:ro
    restart: unless-stopped
    depends_on:
      - loki

  # â”€â”€ Tempo (distributed tracing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  tempo:
    image: grafana/tempo:2.4.1
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./observability/tempo.yaml:/etc/tempo.yaml:ro
      - tempo_data:/tmp/tempo
    ports:
      - "3200:3200"   # Tempo API
    restart: unless-stopped

  # â”€â”€ Grafana â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  grafana:
    image: grafana/grafana:11.1.0
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_FEATURE_TOGGLES_ENABLE=traceToMetrics tempoServiceGraph
      - GF_ANALYTICS_REPORTING_ENABLED=false
    volumes:
      - ./observability/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./observability/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    restart: unless-stopped
    depends_on:
      - prometheus
      - loki
      - tempo

  # â”€â”€ Traefik (load balancer / reverse proxy) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  traefik:
    image: traefik:v3.0
    command:
      - --api.dashboard=true
      - --api.insecure=true
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --providers.file.directory=/etc/traefik/dynamic
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --metrics.prometheus=true
      - --metrics.prometheus.addentrypointslabels=true
      - --metrics.prometheus.addserviceslabels=true
      - --tracing.otlp=true
      - --tracing.otlp.grpc.endpoint=otel-collector:4317
      - --tracing.otlp.grpc.insecure=true
      - --log.format=json
      - --accesslog=true
      - --accesslog.format=json
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traffic/traefik/dynamic:/etc/traefik/dynamic:ro
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"   # Traefik dashboard
    restart: unless-stopped
    depends_on:
      - otel-collector
{f"""
  # â”€â”€ Langfuse (AI Agent Observability) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  langfuse:
    image: langfuse/langfuse:latest
    environment:
      - DATABASE_URL=postgresql://langfuse:langfuse@langfuse-db:5432/langfuse
      - NEXTAUTH_SECRET=your-secret-here
      - NEXTAUTH_URL=http://localhost:4000
      - SALT=your-salt-here
    ports:
      - "4000:3000"
    restart: unless-stopped
    depends_on:
      - langfuse-db

  langfuse-db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: langfuse
      POSTGRES_PASSWORD: langfuse
      POSTGRES_DB: langfuse
    volumes:
      - langfuse_db_data:/var/lib/postgresql/data
""" if agents else ""}

volumes:
  prometheus_data:
  alertmanager_data:
  loki_data:
  tempo_data:
  grafana_data:
{"""  langfuse_db_data:""" if agents else ""}

networks:
  default:
    name: {project}-observability
'''


def generate_otel_config(env: str, agents: bool) -> str:
    return f'''# OpenTelemetry Collector Config â€” {env}
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  prometheus:
    config:
      scrape_configs:
        - job_name: otel-collector
          static_configs:
            - targets: ["0.0.0.0:8888"]

processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128
  batch:
    send_batch_size: 1000
    timeout: 1s
  resource:
    attributes:
      - action: insert
        key: deployment.environment
        value: {env}
  filter/spans:
    spans:
      exclude:
        match_type: regexp
        attributes:
          - key: http.url
            value: ".*/health.*|.*/metrics.*"

connectors:
  spanmetrics:
    histogram:
      explicit:
        buckets: [5ms, 10ms, 50ms, 100ms, 500ms, 1s, 5s]
    dimensions:
      - name: http.method
      - name: http.status_code
      - name: service.name
    exemplars:
      enabled: true

exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    resource_to_telemetry_conversion:
      enabled: true
  otlp/tempo:
    endpoint: "tempo:4317"
    tls:
      insecure: true
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    labels:
      resource:
        service.name: "service_name"
        deployment.environment: "env"
  debug:
    verbosity: basic
    sampling_initial: 2
    sampling_thereafter: 500

extensions:
  health_check:
    endpoint: "0.0.0.0:13133"

service:
  extensions: [health_check]
  pipelines:
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, resource, batch]
      exporters: [prometheus]
    metrics/spanmetrics:
      receivers: [spanmetrics]
      processors: [batch]
      exporters: [prometheus]
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resource, filter/spans, batch]
      exporters: [otlp/tempo, spanmetrics]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [loki]
  telemetry:
    metrics:
      address: 0.0.0.0:8888
'''


def generate_prometheus_config(project: str) -> str:
    return f'''# Prometheus Config â€” {project}
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    project: "{project}"

rule_files:
  - /etc/prometheus/rules/*.yaml

alerting:
  alertmanagers:
    - static_configs:
        - targets: ["alertmanager:9093"]

scrape_configs:
  - job_name: otel-collector
    static_configs:
      - targets: ["otel-collector:8889"]

  - job_name: traefik
    static_configs:
      - targets: ["traefik:8080"]
    metrics_path: /metrics

  - job_name: docker-containers
    dockerswarm_sd_configs:
      - host: unix:///var/run/docker.sock
        role: tasks
    relabel_configs:
      - source_labels: [__meta_dockerswarm_task_label_prometheus_scrape]
        action: keep
        regex: "true"
'''


def generate_grafana_datasources(agents: bool) -> str:
    extras = ""
    if agents:
        extras = """
  - name: Langfuse
    type: postgres
    url: langfuse-db:5432
    database: langfuse
    user: langfuse
    secureJsonData:
      password: langfuse
    jsonData:
      sslmode: disable
"""
    return f'''apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    isDefault: true
    jsonData:
      timeInterval: 15s
      exemplarTraceIdDestinations:
        - datasourceUid: tempo
          name: trace_id

  - name: Loki
    type: loki
    url: http://loki:3100
    jsonData:
      derivedFields:
        - name: TraceID
          matcherRegex: '"trace_id":"(\\w+)"'
          url: "${{__value.raw}}"
          datasourceUid: tempo

  - name: Tempo
    type: tempo
    uid: tempo
    url: http://tempo:3200
    jsonData:
      tracesToLogsV2:
        datasourceUid: loki
        filterByTraceID: true
      serviceMap:
        datasourceUid: prometheus
      nodeGraph:
        enabled: true
{extras}
'''


def generate_makefile(project: str, tier: int) -> str:
    return f'''# {project} â€” Observability Platform Makefile
# Tier {tier}: {TIER_DESCRIPTIONS[tier]}

.PHONY: up down restart logs status check-health

# Start the full observability stack
up:
\tdocker compose -f docker-compose.yaml -f docker-compose.observability.yaml up -d
\t@echo "\\nâœ“ Stack running. URLs:"
\t@echo "  Grafana:      http://localhost:3000"
\t@echo "  Prometheus:   http://localhost:9090"
\t@echo "  Alertmanager: http://localhost:9093"
\t@echo "  Loki:         http://localhost:3100"
\t@echo "  Tempo:        http://localhost:3200"
\t@echo "  Traefik:      http://localhost:8080"
\t@echo "  OTel gRPC:    localhost:4317"
\t@echo "  OTel HTTP:    localhost:4318"

down:
\tdocker compose -f docker-compose.yaml -f docker-compose.observability.yaml down

restart:
\tdocker compose -f docker-compose.yaml -f docker-compose.observability.yaml restart

logs:
\tdocker compose -f docker-compose.observability.yaml logs -f --tail=100

status:
\tdocker compose -f docker-compose.observability.yaml ps

check-health:
\t@curl -sf http://localhost:13133 > /dev/null && echo "âœ“ OTel Collector healthy" || echo "âœ— OTel Collector down"
\t@curl -sf http://localhost:9090/-/healthy > /dev/null && echo "âœ“ Prometheus healthy" || echo "âœ— Prometheus down"
\t@curl -sf http://localhost:3100/ready > /dev/null && echo "âœ“ Loki healthy" || echo "âœ— Loki down"
\t@curl -sf http://localhost:3200/ready > /dev/null && echo "âœ“ Tempo healthy" || echo "âœ— Tempo down"
\t@curl -sf http://localhost:3000/api/health > /dev/null && echo "âœ“ Grafana healthy" || echo "âœ— Grafana down"

# Load sample dashboards from Grafana community
load-dashboards:
\t@echo "Loading standard dashboards..."
\t@curl -s -X POST http://admin:admin@localhost:3000/api/dashboards/import \
\t\t-H "Content-Type: application/json" \
\t\t-d @dashboards/golden-signals.json

# Run cost analysis (requires infracost)
cost-estimate:
\tinfracost breakdown --path=./terraform --format=table

# Validate OTel config
validate-otel-config:
\tdocker run --rm -v $(PWD)/observability/otel-collector-config.yaml:/tmp/config.yaml \
\t\totel/opentelemetry-collector-contrib:0.116.0 validate --config=/tmp/config.yaml
'''


def generate_readme(project: str, tier: int, env: str, traffic: str, agents: bool, cost: bool) -> str:
    return f'''# {project} â€” Observability, Traffic & Cost Platform

**Tier {tier}**: {TIER_DESCRIPTIONS[tier]}
**Environment**: {ENV_OPTIONS.get(env, env)}
**Traffic**: {TRAFFIC_OPTIONS.get(traffic, traffic)}
**AI Agent Observability**: {"Enabled (Langfuse + OTel GenAI)" if agents else "Disabled"}
**Cost Engineering**: {"Enabled" if cost else "Disabled"}

Generated: {datetime.now().strftime("%Y-%m-%d")} by obs-cost-traffic skill

## Quick Start

```bash
# Start observability stack
make up

# Check health
make check-health

# View logs
make logs

# Open dashboards
open http://localhost:3000   # Grafana (anonymous access)
open http://localhost:9090   # Prometheus
open http://localhost:8080   # Traefik dashboard
```

## Stack Components

| Service | Port | URL |
|---------|------|-----|
| Grafana | 3000 | http://localhost:3000 |
| Prometheus | 9090 | http://localhost:9090 |
| Alertmanager | 9093 | http://localhost:9093 |
| Loki | 3100 | http://localhost:3100 |
| Tempo | 3200 | http://localhost:3200 |
| Traefik | 8080 | http://localhost:8080 |
| OTel gRPC | 4317 | â€” |
| OTel HTTP | 4318 | â€” |
{f"| Langfuse | 4000 | http://localhost:4000 |" if agents else ""}

## Instrumenting Your Services

### Python
```python
# pip install opentelemetry-sdk opentelemetry-exporter-otlp
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry import trace

provider = TracerProvider()
provider.add_span_processor(BatchSpanProcessor(
    OTLPSpanExporter(endpoint="http://localhost:4317", insecure=True)
))
trace.set_tracer_provider(provider)

# Or use Docker environment variable:
# OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
```

### Node.js
```bash
npm install @opentelemetry/sdk-node @opentelemetry/exporter-trace-otlp-grpc
```

### Environment Variables (Docker services)
```yaml
environment:
  - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
  - OTEL_SERVICE_NAME=my-service
  - OTEL_RESOURCE_ATTRIBUTES=deployment.environment=dev
  - OTEL_TRACES_SAMPLER=parentbased_traceidratio
  - OTEL_TRACES_SAMPLER_ARG=0.1
```

## File Structure

```
{project}/
â”œâ”€â”€ docker-compose.observability.yaml  # OTel stack
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ otel-collector-config.yaml     # OTel Collector pipelines
â”‚   â”œâ”€â”€ prometheus.yml                 # Scrape config
â”‚   â”œâ”€â”€ rules/                         # Alerting + recording rules
â”‚   â”œâ”€â”€ alertmanager.yml               # Alert routing
â”‚   â”œâ”€â”€ loki.yaml                      # Loki log storage config
â”‚   â”œâ”€â”€ tempo.yaml                     # Tempo trace storage config
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ provisioning/              # Auto-provisioned datasources
â”‚       â””â”€â”€ dashboards/                # Dashboard JSONs
â”œâ”€â”€ traffic/
â”‚   â””â”€â”€ traefik/
â”‚       â””â”€â”€ dynamic/                   # Traefik dynamic routing
â”œâ”€â”€ cost/
â”‚   â””â”€â”€ budget-config.yaml             # Cost budgets and tagging
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## References

- OpenTelemetry: https://opentelemetry.io/docs/
- Prometheus: https://prometheus.io/docs/
- Grafana: https://grafana.com/docs/grafana/latest/
- Loki: https://grafana.com/docs/loki/latest/
- Tempo: https://grafana.com/docs/tempo/latest/
- Traefik: https://doc.traefik.io/traefik/
- FinOps Framework: https://www.finops.org/framework/
'''


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main Scaffold Logic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scaffold(args) -> None:
    project = args.name.lower().replace(" ", "-")
    out = Path(args.output) / project
    tier = args.tier
    env = args.env
    traffic = args.traffic or _default_traffic(tier, env)
    agents = args.agents
    cost = args.cost

    print(f"\nðŸ”­ OBSÂ·COSTÂ·TRAFFIC Scaffold")
    print(f"   Project: {project}")
    print(f"   Tier:    {tier} â€” {TIER_DESCRIPTIONS[tier]}")
    print(f"   Env:     {env} â€” {ENV_OPTIONS.get(env, env)}")
    print(f"   Traffic: {traffic}")
    print(f"   Agents:  {'Yes' if agents else 'No'}")
    print(f"   Cost:    {'Yes' if cost else 'No'}")
    print(f"   Output:  {out}/\n")

    if out.exists() and not args.force:
        print(f"Error: {out} already exists. Use --force to overwrite.")
        sys.exit(1)

    # â”€â”€ Tier 1: Local Dev â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if tier == 1:
        # Docker Compose
        write_file(
            out / "docker-compose.observability.yaml",
            generate_docker_compose(project, env, agents, traffic)
        )

        # OTel Collector config
        write_file(
            out / "observability" / "otel-collector-config.yaml",
            generate_otel_config(env, agents)
        )

        # Prometheus
        write_file(
            out / "observability" / "prometheus.yml",
            generate_prometheus_config(project)
        )

        # Grafana datasources
        write_file(
            out / "observability" / "grafana" / "provisioning" / "datasources" / "datasources.yaml",
            generate_grafana_datasources(agents)
        )

        # Alertmanager (minimal)
        write_file(out / "observability" / "alertmanager.yml", """
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default'

receivers:
  - name: default
    # Add Slack/email here
""")

        # Loki config
        write_file(out / "observability" / "loki.yaml", """
auth_enabled: false
server:
  http_listen_port: 3100
ingester:
  chunk_idle_period: 3m
  max_chunk_age: 1h
schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h
storage_config:
  tsdb_shipper:
    active_index_directory: /loki/tsdb-index
    cache_location: /loki/tsdb-cache
  filesystem:
    directory: /loki/chunks
limits_config:
  retention_period: 7d
  ingestion_rate_mb: 16
  max_label_names_per_series: 20
""")

        # Tempo config
        write_file(out / "observability" / "tempo.yaml", """
server:
  http_listen_port: 3200
distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/blocks
    wal:
      path: /tmp/tempo/wal
compactor:
  compaction:
    block_retention: 168h
""")

        # Traefik dynamic config
        write_file(out / "traffic" / "traefik" / "dynamic" / "middlewares.yaml", """
http:
  middlewares:
    rate-limit:
      rateLimit:
        average: 100
        burst: 50
    circuit-breaker:
      circuitBreaker:
        expression: "ResponseCodeRatio(500, 600, 0, 600) > 0.25"
        checkPeriod: 10s
        fallbackDuration: 10s
        recoverDuration: 10s
""")

    # â”€â”€ Cost config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cost:
        write_file(out / "cost" / "budget-config.yaml", f"""
# Cost Engineering Config â€” {project}
# Edit amounts and tag values for your organization
aws:
  budgets:
    - name: {project}-monthly
      amount_usd: 1000
      type: COST
      time_unit: MONTHLY
  required_tags:
    - env
    - team
    - service
    - cost-center

finops:
  framework_phase: crawl
  observability_cost_limit:
    percent_of_total_cloud_spend: 5
    strategies:
      - sample_info_logs_at: 10%
      - tail_sample_traces_at: 10%
""")

    # â”€â”€ Prometheus rules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    write_file(out / "observability" / "rules" / "golden-signals.yaml", """
groups:
  - name: golden_signals
    rules:
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
          / sum(rate(http_requests_total[5m])) by (job) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.job }} error rate > 5%"

      - alert: HighLatency
        expr: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (job, le)
          ) > 2.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "{{ $labels.job }} p99 latency > 2s"
""")

    # â”€â”€ Makefile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    write_file(out / "Makefile", generate_makefile(project, tier))

    # â”€â”€ README â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    write_file(
        out / "README.md",
        generate_readme(project, tier, env, traffic, agents, cost)
    )

    # â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total = sum(1 for _ in out.rglob("*") if _.is_file())
    print(f"\nâœ… Generated {total} files in {out}/")
    print("\nNext steps:")
    print(f"  cd {out}")
    print("  make up")
    print("  make check-health")
    print("  open http://localhost:3000  # Grafana")


def _default_traffic(tier: int, env: str) -> str:
    if tier == 1:
        return "traefik"
    elif tier == 2:
        return "haproxy"
    elif tier == 3:
        if env == "aws":
            return "alb"
        elif env == "gcp":
            return "cloud-lb"
        elif env == "azure":
            return "app-gateway"
        return "istio"
    else:
        return "cloudflare"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="OBS-COST-TRAFFIC Scaffold â€” Generate production observability projects",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Tier 1: Local dev with Docker Compose (simplest start)
  python scaffold_obs.py --name my-platform --tier 1 --env local

  # Tier 1 with AI agent observability (Langfuse)
  python scaffold_obs.py --name ai-platform --tier 1 --env local --agents

  # Tier 2: VPS with HAProxy + full OSS stack
  python scaffold_obs.py --name prod-obs --tier 2 --env vps --traffic haproxy --cost

  # Tier 3: AWS EKS with Istio + Kubecost
  python scaffold_obs.py --name aws-platform --tier 3 --env aws --traffic istio --cost --agents

  # Tier 4: Enterprise multi-cloud with Cloudflare + Datadog
  python scaffold_obs.py --name enterprise --tier 4 --env multi-cloud --traffic cloudflare --cost --agents
        """
    )

    parser.add_argument("--name", required=True, help="Project name (e.g. my-platform)")
    parser.add_argument("--tier", type=int, choices=[1, 2, 3, 4], default=1,
                        help="Tier 1=Local, 2=VPS, 3=Cloud, 4=Enterprise")
    parser.add_argument("--env", choices=list(ENV_OPTIONS.keys()), default="local",
                        help="Target environment")
    parser.add_argument("--traffic", choices=list(TRAFFIC_OPTIONS.keys()), default=None,
                        help="Traffic/load balancer tool (default: auto based on tier+env)")
    parser.add_argument("--agents", action="store_true",
                        help="Add AI agent observability (Langfuse + OTel GenAI conventions)")
    parser.add_argument("--cost", action="store_true",
                        help="Add cost engineering configs (budgets, tagging, FinOps)")
    parser.add_argument("--output", default=".", help="Output directory (default: current)")
    parser.add_argument("--force", action="store_true", help="Overwrite existing directory")

    args = parser.parse_args()
    scaffold(args)


if __name__ == "__main__":
    main()
